# Project Overview
This project offers users a Flask-leveraged web-based search engine to search for Wikipedia articles relating to the topic of health. The search engine queries our data set, which is an inverted index built from a corpus of ~500 Wikipedia articles. The documents are returned based on relevance to the query using the Okapi BM25 algorithm. Additionally, text summaries of each article are included in the search results as well as pagination for convenient browsing through results.

# Python Scripts
We leveraged several Python scripts to execute multiple different functions necessary for the search engine to run. First, the **Focused Crawler** sources Wikipedia articles based on a seed URL and keyword. For our seed URL, we used https://en.wikipedia.org/wiki/Health, and the keyword we used was "health." Next, we set the depth parameter to 10 so that the crawler would go 10 levels deep in Wikipedia space by adding links to articles within the articles that contained the word "health," through 10 iterations of crawling.

The other key Python scripts include:


**Search Engine**: Builds inverted index from corpus generated by the Focused Crawler, and produces URL results for a given query by running that query against the inverted index and ranking documents based on the Okapi BM25 algorithm.


**Text Summarizer**: Provides most salient sentences in summary form from each URL present in the corpus.


**app.py**: Employs Flask library to generate search engine webpage, takes in user query and runs it through the Search Engine Python script, and contains important logic for appending the correct text summarizies to each URL result, as well as pagination information for use in the index.html file. Each result page should only contain 10 results, and the user should be able to proceed through pages individually until they reach the termination of the search results.

# HTML and CSS Files
The **index.html** and **base.html** files provide the back-end structure of the search engine webpage. The **index.html** file contains Jinja2 scripting to incorporate logic into the web page's layout dependent on certain conditions. For example, if a user reaches the last page of a certain query's results, they should not be able to click on the next page button since there wouldn't be a next page. Another instance of Jinja2 logic is modifying what is shown on the home page compared to post-search. The user does not need to see an empty section labeled with "No Search Results" on the homepage before they have even executed a query. The **base.html** file contains HTML code for visual aspects like font color and so forth.

# Integration with Visual Studio Code and Heroku
To make all these scripts work together, we first ran locally the **inv_index.py** and **text_summarizer.py** files to generate pickle files of the inverted index and text summaries of all the documents in the corpus, and saved those to a local directory. Next, those pickle files were accessed by the **app.py** file run in a VS Code environment in a directory which also contained the **search_engine.py** file along with the HTML and CSS files. Finally, a Heroku account was setup and the webpage was generated via the Heroku CLI.
