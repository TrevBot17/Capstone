{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f441f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5f913b",
   "metadata": {},
   "source": [
    "### Query transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform a given query into a list of tokenized+stemmed words (same pre-processing steps applied as it \n",
    "# was done for creating the inverted index)\n",
    "\n",
    "def query_prep(query):\n",
    "    \"\"\"convert a given query into a list of tokenized and stemmed words\"\"\"\n",
    "    \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    word_tokens = nltk.word_tokenize(query)\n",
    "    tokens_swremoved = [w for w in word_tokens if w.lower() not in stop_words]\n",
    "    tokens_stemmed = [stemmer.stem(w) for w in tokens_swremoved]\n",
    "    tokens_puncremoved = [token for token in tokens_stemmed if token not in punctuation]\n",
    "    \n",
    "    return tokens_puncremoved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a367202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load inverted index\n",
    "with open(\"app/inv_index.pickle\", \"rb\") as file:\n",
    "    inv_index = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b0dd4",
   "metadata": {},
   "source": [
    "### Retrieval function with TF maximum frequency normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve and rank the webpages/documents given a query\n",
    "\n",
    "def retrieve_n_rank_docs(inverted_index, queries, max_docs=-1):\n",
    "    \"\"\"\n",
    "    Retrieve webpages in order of relevance from an inverted index based on a query. The function looks only \n",
    "    at terms of the query which are present in the inverted index. The ranking is based on the retrieval function \n",
    "    S(D, Q)=sum(TF(w,D)*IDF(w)*QTF(w)), where TF is caclulated using maximum frequency \n",
    "    normalization TF(w,D)=0.5+(0.5xc(w,D)/MaxFreq_w(D)), and IDF(w)=1+ln(n/k). The query term frequency (QTF) is just\n",
    "    the occurrence of the word in the query. \n",
    "    \n",
    "    - input: inverted index, query, max_docs (max number of docs to be retrieved)\n",
    "    - returns the webpages in descending order of relevance\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ret_docs = None\n",
    "      \n",
    "    # dict for collecting maxFreqw(D) for calulation of normlized TF using maximum frequency normalization, \n",
    "    # traverse through all documents in the given inverted index and search for maximum frequency of a word in a document\n",
    "    max_freq_wD_dict = {}\n",
    "    for token, posting in inverted_index.items():\n",
    "        for key, val in posting.items():\n",
    "            if key not in max_freq_wD_dict:\n",
    "                max_freq_wD_dict[key] = val[0]\n",
    "            elif val[0] > max_freq_wD_dict[key]:\n",
    "                max_freq_wD_dict[key] = val[0]\n",
    "                \n",
    "    ret_docs= {}\n",
    "\n",
    "    for query in queries:\n",
    "        # dict for each query (temporary)\n",
    "        docs = {}\n",
    "        for token in queries[query]:\n",
    "            # check if token is in index\n",
    "            if token in inverted_index.keys():\n",
    "                # IDF: formula: 1 + ln(N/df(w)), Note: IDF is not dependent on a particular document!\n",
    "                idf = 1 + math.log(len(max_freq_wD_dict) / len(inverted_index[token]))\n",
    "                # traverse through the documents in the inverted index for the given token, calculate TF*IDF and\n",
    "                # store the per-document accumulated version of it in dict docs\n",
    "                # (dictionary accumulating pattern)\n",
    "                for doc in inverted_index[token]:\n",
    "                    # calculation of TF*IDF (with normalized version of TF using maxFreqw(D) from dict max_freq_wD_dict)\n",
    "                    c_wD = inverted_index[token][doc][0]\n",
    "                    max_freq_wD = max_freq_wD_dict[doc]\n",
    "                    tfidf = (0.5 + (0.5 * c_wD / max_freq_wD)) * idf \n",
    "                    if doc not in docs:\n",
    "                        docs[doc] = tfidf\n",
    "                    else:\n",
    "                        docs[doc] += tfidf\n",
    "                        \n",
    "        # rounding before sorting\n",
    "        docs = {k: round(v,3) for k, v in docs.items()}\n",
    "\n",
    "        # options for max_docs\n",
    "        if max_docs == -1:\n",
    "            docs_per_query = sorted(Counter(docs).most_common(), key=lambda x: (-x[1], int(x[0][0].split('d')[1])))\n",
    "        else:\n",
    "            docs_per_query = sorted(Counter(docs).most_common(), key=lambda x: (-x[1], int(x[0][0].split('d')[1])))[:max_docs]\n",
    "        # grab the doc id out of docs_per_query\n",
    "        ret_docs[query] = [(doc,freq) for doc, freq in docs_per_query]\n",
    "                \n",
    "    return ret_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ddf824",
   "metadata": {},
   "source": [
    "### Okapi/BM25 Retrieval function (Robertson et al., 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5654aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OkapiBM25 version of the retrieval function\n",
    "def OkapiBM25(inverted_index, queries, max_docs=-1, k1=1.2, b=0.75, k3=1000):\n",
    "    \"\"\"\n",
    "    Retrieve webpages in order of relevance from an inverted index based on a query. The function looks only \n",
    "    at terms of the query which are present in the inverted index. The ranking is based on the retrieval function \n",
    "    S(D, Q)=sum(((k1+1)*c_wD)/(k1*(1-b+b*(|D|/avg_dl))+c_wD) * ln((N-df(w)+0.5)/(df(w)+0.5) * ((k3+1)*c_wQ)/(k3+c_wQ)). \n",
    "    \n",
    "    - input: inverted index, query, max_docs (max number of docs to be retrieved), and parameters k1, b, k3\n",
    "    - returns the webpages in descending order of relevance\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # dict for storing the document length\n",
    "    doc_dict = {}\n",
    "    for token, posting in inverted_index.items():\n",
    "        for doc, val in posting.items():\n",
    "            if doc not in doc_dict:\n",
    "                doc_dict[doc] = val[0]\n",
    "            else:\n",
    "                doc_dict[doc] += val[0]\n",
    "    # average doc length\n",
    "    avg_dl = np.mean([value for key, value in doc_dict.items()]) \n",
    "\n",
    "    ret_docs= {}            \n",
    "\n",
    "    for query in queries:\n",
    "        # dict for each query (temporary)\n",
    "        docs = {}\n",
    "        for token in queries[query]:\n",
    "            # calculate query term frequency c_wQ\n",
    "            c_wQ = queries[query].count(token)\n",
    "            # check if token is in index\n",
    "            if token in inverted_index.keys():\n",
    "                # IDF: formula: ln((N-df(w)+0.5)/(df(w)+0.5), Note: IDF is not dependent on a particular document!\n",
    "                idf = math.log((len(doc_dict)-len(inverted_index[token])+0.5)/(len(inverted_index[token])+0.5))\n",
    "                # traverse through the documents in the inverted index for the given token, calculate the score per token \n",
    "                # using Okapi/BM25 and store the per-document accumulated version of it in dict docs\n",
    "                # (dictionary accumulating pattern)\n",
    "                for doc in inverted_index[token]:\n",
    "                    # TF=((k1+1)*c_wD)/(k1*(1-b+b*(|D|/avg_dl)+c_wD))\n",
    "                    c_wD = inverted_index[token][doc][0]\n",
    "                    tf = ((k1 + 1) * c_wD) / (k1*(1 - b + b * (doc_dict[doc]/avg_dl)) + c_wD)\n",
    "                    # normalized query term frequency: qtf=((k3+1)*c_wQ)/(k3+c_wQ)\n",
    "                    qtf = ((k3 + 1) * c_wQ) / (k3 + c_wQ)\n",
    "                    score = tf * idf * qtf\n",
    "                    if doc not in docs:\n",
    "                        docs[doc] = score\n",
    "                    else:\n",
    "                        docs[doc] += score\n",
    "                        \n",
    "        # rounding before sorting\n",
    "        docs = {k: round(v,3) for k, v in docs.items()}\n",
    "\n",
    "        # options for max_docs\n",
    "        if max_docs == -1:\n",
    "            docs_per_query = sorted(Counter(docs).most_common(), key=lambda x: (-x[1], int(x[0][0].split('d')[1])))\n",
    "        else:\n",
    "            docs_per_query = sorted(Counter(docs).most_common(), key=lambda x: (-x[1], int(x[0][0].split('d')[1])))[:max_docs]\n",
    "        # grab the doc id out of docs_per_query\n",
    "        ret_docs[query] = [(doc,freq) for doc, freq in docs_per_query]\n",
    "                \n",
    "    return ret_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ff92f",
   "metadata": {},
   "source": [
    "### Queries by Users Trevor, Julien, Andr√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a373ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries from users\n",
    "query_list = ['speech language pathology',\n",
    "              'mental health in college',\n",
    "              'healthcare in different countries',\n",
    "              'major health legislation',\n",
    "              'impact of climate change',\n",
    "              'dental healthcare united states',\n",
    "              'help my child develop healthy behaviors',\n",
    "              'relationship between womens rights and health outcomes',\n",
    "              'healthcare in asian countries',\n",
    "              'effects of smoking',\n",
    "              'LGBTQ healthcare',\n",
    "              'country with best healthcare',\n",
    "              'Impact of weight on health',\n",
    "              'What causes lung cancer?', \n",
    "              'Incubation period flu virus', \n",
    "              'Cost health insurance Germany',\n",
    "              'Impact of personal lifestyle on health issues', \n",
    "              'How can nutrition influence mental and physical wellbeing?', \n",
    "              'Homeopathy in Europe', \n",
    "              'Mental disorder in children', \n",
    "              'medical conditions aborigines', \n",
    "              'stillbirths in the United States',\n",
    "              'Is veganism healthy',\n",
    "              'long-term effects of eating processed foods',\n",
    "              'efficacy of quadruple bypass surgery',\n",
    "              'Is Gilberts syndrome benign',\n",
    "              'corruption in the pharmaceutical industry',\n",
    "              'is vaping safe',\n",
    "              'relationship between air pollution and respiratory health',\n",
    "              'will loud music cause hearing loss']\n",
    "\n",
    "queries = {}\n",
    "c = 1\n",
    "for query in query_list:\n",
    "    queries[f'q{c}'] = query_prep(query)\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b5db0f",
   "metadata": {},
   "source": [
    "#### Generate top 5 rankings per query with both OkapiBM25 and Maximum Frequency Normalization retrieval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb73226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking with OkapiBM25 and TF Maximum Frequency Normalization \n",
    "ranking_okapi = OkapiBM25(inv_index, queries, max_docs=5, k1=1.2, b=0.75, k3=1000)\n",
    "ranking_maxfreqn = retrieve_n_rank_docs(inv_index, queries, max_docs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries2 = {}\n",
    "c = 1\n",
    "for query in query_list:\n",
    "    queries2[f'q{c}'] = query, query_prep(query)\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb77326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame for OkapiBM25\n",
    "l=[]\n",
    "q_id = 1\n",
    "for q in ranking_okapi:  \n",
    "    for r in ranking_okapi[q]:\n",
    "        l.append((f'q{q_id}',queries2[q][0],queries2[q][1],r[0][0],r[0][1],r[1]))\n",
    "    q_id += 1\n",
    "\n",
    "df_okapi = pd.DataFrame(l, columns=['Query ID','Query','Stemmed Query','docID_Okapi','Result_Okapi','Score_Okapi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac1928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame for TF Maximum Frequency Normalization\n",
    "l2 = []\n",
    "q_id = 1\n",
    "for q in ranking_maxfreqn:  \n",
    "    for r in ranking_maxfreqn[q]:\n",
    "        l2.append((f'q{q_id}',queries2[q][0],queries2[q][1],r[0][0],r[0][1],r[1]))\n",
    "    q_id += 1\n",
    "\n",
    "df_maxfreqn = pd.DataFrame(l2, columns=['Query ID','Query','Stemmed Query','docID_MaxFreq','Result_MaxFreq','Score_MaxFreq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42aad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final DataFrame which can be used to create the Ground Truth\n",
    "pd.concat([df_okapi, df_maxfreqn], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
